{"cells":[{"cell_type":"markdown","metadata":{"id":"ErLzyl68ropJ"},"source":["Alice Simon, Céline Carré et Lucie Engel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27446,"status":"ok","timestamp":1680533650964,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"},"user_tz":-120},"id":"ahqBe8o3r3yx","outputId":"5103478f-1ad7-4336-af67-fc593b27a878"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"-2K1mU6ZropO"},"source":["# Introduction\n","\n","https://www.kaggle.com/code/vatsalmavani/pytorch-lung-segmentation-using-pretrained-u-net"]},{"cell_type":"markdown","metadata":{"id":"LVUMvCp6ropP"},"source":["# Dataset\n","\n","The data collected at baseline include breast ultrasound images among women in ages between 25 and 75 years old. This data was collected in 2018. The number of patients is 600 female patients. The dataset consists of 780 images with an average image size of 500*500 pixels. The images are in PNG format. The ground truth images are presented with original images. The images are categorized into three classes, which are normal, benign, and malignant.\n","\n","Reference : Al-Dhabyani W, Gomaa M, Khaled H, Fahmy A. Dataset of breast ultrasound images. Data in Brief. 2020 Feb;28:104863. DOI: 10.1016/j.dib.2019.104863."]},{"cell_type":"markdown","metadata":{"id":"HYuG6x31ropQ"},"source":["!pip install segmentation-models-pytorch# Load data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"5gP0x3_rropQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680533660899,"user_tz":-120,"elapsed":9943,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"}},"outputId":"f37017d7-7092-495b-c812-9b3c92c3c9e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.14.1+cu116)\n","Collecting timm==0.6.12\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pretrainedmodels==0.7.4\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (8.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (4.65.0)\n","Collecting efficientnet-pytorch==0.7.1\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1+cu116)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.27.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.10.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16444 sha256=e53707793d2a2a9530c53f601c7633a1cb2bd18ac0b5df8d1b9e56b57a431b65\n","  Stored in directory: /root/.cache/pip/wheels/29/16/24/752e89d88d333af39a288421e64d613b5f652918e39ef1f8e3\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=8203086e001a29450000a627cfc3badc7794f7b3057b7ccb11e99e28cf7d046a\n","  Stored in directory: /root/.cache/pip/wheels/d1/3b/4e/2f3015f1ab76f34be28e04c4bcee27e8cabfa70d2eadf8bc3b\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, huggingface-hub, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.13.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.2 timm-0.6.12\n"]}],"source":["!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcldQZQ8ropS"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import pathlib\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, transforms \n","import os \n","import pandas as pd\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import torch.optim as optim \n","torch.manual_seed(25)\n","import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680533664583,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"},"user_tz":-120},"id":"aRuulnJ9ropT","outputId":"888f58ab-278b-427f-d9d3-45def87b72a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Projet_DL/Dataset_BUSI_with_GT\n"]}],"source":["cd \"/content/drive/MyDrive/Projet_DL/Dataset_BUSI_with_GT\""]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"3n4vyquQdzx8","executionInfo":{"status":"ok","timestamp":1680533665065,"user_tz":-120,"elapsed":12,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"}},"outputId":"4ee31d33-7800-4085-b852-0996a3c42858"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kONDElW3ropU"},"outputs":[],"source":["# inspi https://www.kaggle.com/code/vanvalkenberg/segmentation-model-for-breast-cancer\n","\n","def load_data(path, shape):\n","    names = os.listdir(path)\n","    \n","    patient_num = []\n","    ultrasound_path = []\n","    mask_path = []\n","    \n","    for i in range(len(names)):\n","        patient_num.append(names[i].split(')')[0])\n","\n","    patient_num = list(set(patient_num))\n","\n","    for i in range(len(patient_num)):\n","        ultrasound_name = patient_num[i]+').png'\n","        mask_name = patient_num[i]+')_mask.png'\n","        ultrasound_path.append(os.path.join(path,ultrasound_name))\n","        mask_path.append(os.path.join(path,mask_name))\n","    \n","    dict = {'ultrasound_path': ultrasound_path, 'mask_path': mask_path, 'class' : [path]*len(ultrasound_path)}\n","    return pd.DataFrame(dict) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":5768,"status":"ok","timestamp":1680533670826,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"},"user_tz":-120},"id":"KiaUxWTBropV","outputId":"4039b06f-f596-4bc0-ad70-599b4aaa8986"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             ultrasound_path                     mask_path   class\n","0    benign/benign (255).png  benign/benign (255)_mask.png  benign\n","1    benign/benign (376).png  benign/benign (376)_mask.png  benign\n","2    benign/benign (404).png  benign/benign (404)_mask.png  benign\n","3    benign/benign (410).png  benign/benign (410)_mask.png  benign\n","4    benign/benign (392).png  benign/benign (392)_mask.png  benign\n","..                       ...                           ...     ...\n","128   normal/normal (68).png   normal/normal (68)_mask.png  normal\n","129   normal/normal (55).png   normal/normal (55)_mask.png  normal\n","130   normal/normal (47).png   normal/normal (47)_mask.png  normal\n","131  normal/normal (129).png  normal/normal (129)_mask.png  normal\n","132   normal/normal (85).png   normal/normal (85)_mask.png  normal\n","\n","[780 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-9fbda6a0-75b6-4605-bcee-345bb92ee3e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ultrasound_path</th>\n","      <th>mask_path</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>benign/benign (255).png</td>\n","      <td>benign/benign (255)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>benign/benign (376).png</td>\n","      <td>benign/benign (376)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>benign/benign (404).png</td>\n","      <td>benign/benign (404)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>benign/benign (410).png</td>\n","      <td>benign/benign (410)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>benign/benign (392).png</td>\n","      <td>benign/benign (392)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>normal/normal (68).png</td>\n","      <td>normal/normal (68)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>normal/normal (55).png</td>\n","      <td>normal/normal (55)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>normal/normal (47).png</td>\n","      <td>normal/normal (47)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>normal/normal (129).png</td>\n","      <td>normal/normal (129)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>normal/normal (85).png</td>\n","      <td>normal/normal (85)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>780 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fbda6a0-75b6-4605-bcee-345bb92ee3e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9fbda6a0-75b6-4605-bcee-345bb92ee3e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9fbda6a0-75b6-4605-bcee-345bb92ee3e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["SHAPE = 256\n","benign_df = load_data('benign', SHAPE)\n","malignant_df = load_data('malignant', SHAPE)\n","normal_df = load_data('normal', SHAPE)\n","\n","data_df = pd.concat([benign_df, malignant_df, normal_df])\n","data_df # 780 exams "]},{"cell_type":"code","source":["data_df = pd.read_csv(\"whole_dataset_df.csv\")"],"metadata":{"id":"hGbLTfByYLe-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tain, Valid and Test Set"],"metadata":{"id":"SEG6CFdbYNvL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4oAZBc0at2gy"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_and_valid_df, test_df = train_test_split(data_df, test_size=0.1, stratify=data_df['class'], random_state = 11)\n","\n","train_and_valid_df # 702 samples\n","test_df # 78 samples\n","\n","train_df, valid_df = train_test_split(train_and_valid_df, test_size=0.2, stratify=train_and_valid_df['class'], random_state = 11)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680533671157,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"},"user_tz":-120},"id":"TRblTaQ2ropW","outputId":"f68c63ee-e1ad-4298-beee-7048e0804cd2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Unnamed: 0                ultrasound_path  \\\n","756         109         normal/normal (28).png   \n","25           25         benign/benign (56).png   \n","457          20  malignant/malignant (198).png   \n","686          39         normal/normal (69).png   \n","510          73   malignant/malignant (19).png   \n","..          ...                            ...   \n","350         350        benign/benign (199).png   \n","327         327        benign/benign (159).png   \n","424         424         benign/benign (93).png   \n","469          32   malignant/malignant (76).png   \n","434         434        benign/benign (136).png   \n","\n","                              mask_path      class  \n","756         normal/normal (28)_mask.png     normal  \n","25          benign/benign (56)_mask.png     benign  \n","457  malignant/malignant (198)_mask.png  malignant  \n","686         normal/normal (69)_mask.png     normal  \n","510   malignant/malignant (19)_mask.png  malignant  \n","..                                  ...        ...  \n","350        benign/benign (199)_mask.png     benign  \n","327        benign/benign (159)_mask.png     benign  \n","424         benign/benign (93)_mask.png     benign  \n","469   malignant/malignant (76)_mask.png  malignant  \n","434        benign/benign (136)_mask.png     benign  \n","\n","[141 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-83bff2aa-edcc-43e7-a76c-8ec678a15f20\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>ultrasound_path</th>\n","      <th>mask_path</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>756</th>\n","      <td>109</td>\n","      <td>normal/normal (28).png</td>\n","      <td>normal/normal (28)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>benign/benign (56).png</td>\n","      <td>benign/benign (56)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>457</th>\n","      <td>20</td>\n","      <td>malignant/malignant (198).png</td>\n","      <td>malignant/malignant (198)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>39</td>\n","      <td>normal/normal (69).png</td>\n","      <td>normal/normal (69)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>73</td>\n","      <td>malignant/malignant (19).png</td>\n","      <td>malignant/malignant (19)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>350</td>\n","      <td>benign/benign (199).png</td>\n","      <td>benign/benign (199)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>327</td>\n","      <td>benign/benign (159).png</td>\n","      <td>benign/benign (159)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>424</td>\n","      <td>benign/benign (93).png</td>\n","      <td>benign/benign (93)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>469</th>\n","      <td>32</td>\n","      <td>malignant/malignant (76).png</td>\n","      <td>malignant/malignant (76)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>434</th>\n","      <td>434</td>\n","      <td>benign/benign (136).png</td>\n","      <td>benign/benign (136)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>141 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83bff2aa-edcc-43e7-a76c-8ec678a15f20')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-83bff2aa-edcc-43e7-a76c-8ec678a15f20 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-83bff2aa-edcc-43e7-a76c-8ec678a15f20');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["train_df # 561 samples\n","valid_df # 141 samples"]},{"cell_type":"code","source":["test_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"yZqxyahWZA38","executionInfo":{"status":"ok","timestamp":1680533671158,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"}},"outputId":"f4d616e2-9eca-4709-d6f3-a63cf2faa199"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Unnamed: 0                ultrasound_path  \\\n","385         385        benign/benign (274).png   \n","301         301        benign/benign (385).png   \n","433         433        benign/benign (196).png   \n","138         138        benign/benign (379).png   \n","573         136   malignant/malignant (37).png   \n","..          ...                            ...   \n","236         236        benign/benign (213).png   \n","472          35   malignant/malignant (74).png   \n","734          87         normal/normal (99).png   \n","564         127   malignant/malignant (73).png   \n","511          74  malignant/malignant (208).png   \n","\n","                              mask_path      class  \n","385        benign/benign (274)_mask.png     benign  \n","301        benign/benign (385)_mask.png     benign  \n","433        benign/benign (196)_mask.png     benign  \n","138        benign/benign (379)_mask.png     benign  \n","573   malignant/malignant (37)_mask.png  malignant  \n","..                                  ...        ...  \n","236        benign/benign (213)_mask.png     benign  \n","472   malignant/malignant (74)_mask.png  malignant  \n","734         normal/normal (99)_mask.png     normal  \n","564   malignant/malignant (73)_mask.png  malignant  \n","511  malignant/malignant (208)_mask.png  malignant  \n","\n","[78 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-6ac63f7c-9e78-4120-a7a9-5afbfc2c2634\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>ultrasound_path</th>\n","      <th>mask_path</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>385</th>\n","      <td>385</td>\n","      <td>benign/benign (274).png</td>\n","      <td>benign/benign (274)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>301</th>\n","      <td>301</td>\n","      <td>benign/benign (385).png</td>\n","      <td>benign/benign (385)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>433</td>\n","      <td>benign/benign (196).png</td>\n","      <td>benign/benign (196)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>138</td>\n","      <td>benign/benign (379).png</td>\n","      <td>benign/benign (379)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>136</td>\n","      <td>malignant/malignant (37).png</td>\n","      <td>malignant/malignant (37)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>236</td>\n","      <td>benign/benign (213).png</td>\n","      <td>benign/benign (213)_mask.png</td>\n","      <td>benign</td>\n","    </tr>\n","    <tr>\n","      <th>472</th>\n","      <td>35</td>\n","      <td>malignant/malignant (74).png</td>\n","      <td>malignant/malignant (74)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>734</th>\n","      <td>87</td>\n","      <td>normal/normal (99).png</td>\n","      <td>normal/normal (99)_mask.png</td>\n","      <td>normal</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>127</td>\n","      <td>malignant/malignant (73).png</td>\n","      <td>malignant/malignant (73)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","    <tr>\n","      <th>511</th>\n","      <td>74</td>\n","      <td>malignant/malignant (208).png</td>\n","      <td>malignant/malignant (208)_mask.png</td>\n","      <td>malignant</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>78 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ac63f7c-9e78-4120-a7a9-5afbfc2c2634')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ac63f7c-9e78-4120-a7a9-5afbfc2c2634 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ac63f7c-9e78-4120-a7a9-5afbfc2c2634');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"awxbqpGxyiK5"},"source":["### Custom Dataset for masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RdIf-xayguc"},"outputs":[],"source":["us_transform = transforms.Compose([   \n","    #transforms.Grayscale(),\n","    transforms.Resize(size=(256,256)),  \n","    transforms.ToTensor()                    \n","])\n","\n","mask_transform = transforms.Compose([  \n","    transforms.Grayscale(),\n","    transforms.Resize(size=(256,256)),  \n","    transforms.ToTensor()                    \n","])\n","                \n","\n","class CustomDataset_mask(Dataset): # on crée le dataset \n","    def __init__(self, dataframe, us_transform = None, mask_transform = None, target_transform = None, print_label = False):\n","        self.df = dataframe\n","        self.us_transform = us_transform\n","        self.mask_transform = mask_transform\n","        self.target_transform = target_transform\n","        self.print_label = print_label\n","    \n","    def __len__(self): # longueur du dataset \n","        return len(self.df)\n","    \n","    def __getitem__(self, idx): # fonction qui permet de récupérer un élément \n","        ultrasound_path = self.df.iloc[idx, self.df.columns.get_loc('ultrasound_path')]\n","        mask_path = self.df.iloc[idx, self.df.columns.get_loc('mask_path')]\n","        label = self.df.iloc[idx, self.df.columns.get_loc('class')]\n","        \n","        ultrasound_img = Image.open(ultrasound_path)     \n","        mask_img = Image.open(mask_path)  \n","        \n","        if self.us_transform:\n","            ultrasound_img = self.us_transform(ultrasound_img)\n","        if self.mask_transform : \n","            mask_img = self.mask_transform(mask_img)\n","        \n","        if label == \"normal\" : label = torch.tensor([1,0,0])\n","        elif label == \"benign\" : label = torch.tensor([0,1,0])\n","        elif label == \"malignant\" : label = torch.tensor([0,0,1])\n","        else : print(\"hay un problema\")\n","\n","        if self.target_transform:   \n","            label = self.target_transform(label)\n","        \n","        if mask_img.shape == torch.Size([3, 256, 256]): print(mask_path)\n","        \n","        if self.print_label == True:\n","            return ultrasound_img, mask_img, label \n","        else:\n","            return ultrasound_img, mask_img \n","    \n","    "]},{"cell_type":"markdown","metadata":{"id":"KDgcF3jJyYAu"},"source":["### Custom Dataset for Label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdXDGWQNropZ"},"outputs":[],"source":["          \n","\n","class CustomDataset_label(Dataset): # on crée le dataset \n","    def __init__(self, dataframe, us_transform = None, mask_transform = None, target_transform = None):\n","        self.df = dataframe\n","        self.us_transform = us_transform\n","        self.mask_transform = mask_transform\n","        self.target_transform = target_transform\n","    \n","    def __len__(self): # longueur du dataset \n","        return len(self.df)\n","    \n","    def __getitem__(self, idx): # fonction qui permet de récupérer un élément \n","        ultrasound_path = self.df.iloc[idx, self.df.columns.get_loc('ultrasound_path')]\n","        mask_path = self.df.iloc[idx, self.df.columns.get_loc('mask_path')]\n","        label = self.df.iloc[idx, self.df.columns.get_loc('class')]\n","        \n","        ultrasound_img = Image.open(ultrasound_path)     \n","        mask_img = Image.open(mask_path).convert('RGB')  \n","        \n","        if self.us_transform:\n","            ultrasound_img = self.us_transform(ultrasound_img)\n","        if self.mask_transform : \n","            mask_img = self.mask_transform(mask_img)\n","        \n","        if label == \"normal\" : label = torch.tensor([1,0,0])\n","        elif label == \"benign\" : label = torch.tensor([0,1,0])\n","        elif label == \"malignant\" : label = torch.tensor([0,0,1])\n","        else : print(\"hay un problema\")\n","\n","        if self.target_transform:   \n","            label = self.target_transform(label)\n","        \n","        if mask_img.shape == torch.Size([3, 256, 256]): print(mask_path)\n","            \n","        return mask_img, label \n","    \n"]},{"cell_type":"markdown","metadata":{"id":"FvQnStEIrope"},"source":["## Model for mask prediction\n","\n","U-Net est un réseau de neurones à convolution développé pour la segmentation d'images biomédicales \n","https://towardsdatascience.com/a-detailed-explanation-of-the-attention-u-net-b371a5590831"]},{"cell_type":"markdown","metadata":{"id":"Apen3NolxOZC"},"source":["### Architecture Unet pretrained"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-h79ZV5y5ng"},"outputs":[],"source":["# LOSSES\n","# source : https://www.kaggle.com/code/vatsalmavani/pytorch-lung-segmentation-using-pretrained-u-net\n","import torch.nn.functional as F\n","\n","def dice_loss(input, target):\n","    input = torch.sigmoid(input)\n","    smooth = 1.0\n","    iflat = input.view(-1)\n","    tflat = target.view(-1)\n","    intersection = (iflat * tflat).sum()\n","    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n","\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma):\n","        super().__init__()\n","        self.gamma = gamma\n","\n","    def forward(self, input, target):\n","        if not (target.size() == input.size()):\n","            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n","                             .format(target.size(), input.size()))\n","        max_val = (-input).clamp(min=0)\n","        loss = input - input * target + max_val + \\\n","            ((-max_val).exp() + (-input - max_val).exp()).log()\n","        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n","        loss = (invprobs * self.gamma).exp() * loss\n","        return loss.mean()\n","\n","\n","class MixedLoss(nn.Module):\n","    def __init__(self, alpha, gamma):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.focal = FocalLoss(gamma)\n","\n","    def forward(self, input, target):\n","        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n","        return loss.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKmGVcXhxBft"},"outputs":[],"source":["# PRE-TRAINED UNET \n","# import segmentation_models_pytorch as smp\n","Encoder = 'resnet34'\n","Weights = 'imagenet'\n","\n","model_mask = smp.Unet(\n","    encoder_name = Encoder,\n","    encoder_weights = Weights,\n","    in_channels = 3,\n","    classes = 1, #tumeur \n","    activation = None  #return logits\n",")\n","model_mask = model_mask.to(device)\n"]},{"cell_type":"code","source":["N_EPOCHS = 30\n","LR = 0.01\n","\n","loss_fn = MixedLoss(alpha = 10.0,gamma = 2.0)\n","opt = optim.Adam(model_mask.parameters(),lr = LR)\n","\n","scheduler = torch.optim.lr_scheduler.LinearLR(opt, start_factor = 1, end_factor= 0.05, total_iters = 20)"],"metadata":{"id":"4OFwkGwGrqOE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIBi8giZzHYh"},"outputs":[],"source":["train_dataset_mask = CustomDataset_mask(train_df, us_transform, mask_transform)\n","valid_dataset_mask = CustomDataset_mask(valid_df, us_transform, mask_transform)\n","test_dataset_mask = CustomDataset_mask(test_df, us_transform, mask_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opnv3tAfzUfF"},"outputs":[],"source":["BATCH_SIZE = 100\n","\n","train_dataloader_mask = DataLoader(dataset = train_dataset_mask, batch_size = BATCH_SIZE, shuffle = True)\n","valid_dataloader_mask = DataLoader(dataset = valid_dataset_mask, batch_size = BATCH_SIZE, shuffle = False)\n","test_dataloader_mask = DataLoader(dataset = test_dataset_mask, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLKbi7ChzgSC"},"outputs":[],"source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    \n","    for batch, (X, y) in enumerate(dataloader):\n","\n","        X = X.to(device)\n","        y = y.to(device)\n","\n","        # Compute prediction and loss\n","        logits = model(X)\n","        loss = loss_fn(logits, y)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % int(BATCH_SIZE/10) == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"train loss: {loss}  [{current}/{size}]\")\n","\n","\n","def test_loop(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            \n","            X = X.to(device)\n","            y = y.to(device)\n","            \n","            logits = model(X)\n","            test_loss += loss_fn(logits, y).item()\n","            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    #correct /= size\n","    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss} \\n\")\n","    print(f\"Test Error: Avg loss: {test_loss} \\n\")\n","    return test_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBgHFtRyzuLZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680540773336,"user_tz":-120,"elapsed":578725,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"}},"outputId":"6b367796-1557-4d19-e7d1-bbbcc69483eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","train loss: 4.627499103546143  [0/561]\n","Test Error: Avg loss: 2.1840384006500244 \n","\n","Before LR :0.01, After LR : 0.009525 \n","\n","Epoch 2\n","-------------------------------\n","train loss: 2.076478958129883  [0/561]\n","Test Error: Avg loss: 1.9252575039863586 \n","\n","Before LR :0.009525, After LR : 0.00905 \n","\n","Epoch 3\n","-------------------------------\n","train loss: 1.8231405019760132  [0/561]\n","Test Error: Avg loss: 1.8554055094718933 \n","\n","Before LR :0.00905, After LR : 0.008575000000000001 \n","\n","Epoch 4\n","-------------------------------\n","train loss: 1.6698434352874756  [0/561]\n","Test Error: Avg loss: 1.5150481462478638 \n","\n","Before LR :0.008575000000000001, After LR : 0.008100000000000001 \n","\n","Epoch 5\n","-------------------------------\n","train loss: 1.3544845581054688  [0/561]\n","Test Error: Avg loss: 1.508501410484314 \n","\n","Before LR :0.008100000000000001, After LR : 0.007625000000000001 \n","\n","Epoch 6\n","-------------------------------\n","train loss: 1.2161719799041748  [0/561]\n","Test Error: Avg loss: 1.586586058139801 \n","\n","Before LR :0.007625000000000001, After LR : 0.007150000000000001 \n","\n","Epoch 7\n","-------------------------------\n","train loss: 1.2791653871536255  [0/561]\n","Test Error: Avg loss: 1.5019448399543762 \n","\n","Before LR :0.007150000000000001, After LR : 0.006675 \n","\n","Epoch 8\n","-------------------------------\n","train loss: 1.3603177070617676  [0/561]\n","Test Error: Avg loss: 1.4776008129119873 \n","\n","Before LR :0.006675, After LR : 0.006200000000000001 \n","\n","Epoch 9\n","-------------------------------\n","train loss: 1.16495680809021  [0/561]\n","Test Error: Avg loss: 1.3767404556274414 \n","\n","Before LR :0.006200000000000001, After LR : 0.005725 \n","\n","Epoch 10\n","-------------------------------\n","train loss: 1.0010782480239868  [0/561]\n","Test Error: Avg loss: 1.2951465845108032 \n","\n","Before LR :0.005725, After LR : 0.00525 \n","\n","Epoch 11\n","-------------------------------\n","train loss: 1.0883327722549438  [0/561]\n","Test Error: Avg loss: 1.285556435585022 \n","\n","Before LR :0.00525, After LR : 0.004775000000000001 \n","\n","Epoch 12\n","-------------------------------\n","train loss: 0.8957276344299316  [0/561]\n","Test Error: Avg loss: 1.4757897853851318 \n","\n","Before LR :0.004775000000000001, After LR : 0.004300000000000001 \n","\n","Epoch 13\n","-------------------------------\n","train loss: 0.8456898331642151  [0/561]\n","Test Error: Avg loss: 1.2887282073497772 \n","\n","Before LR :0.004300000000000001, After LR : 0.0038250000000000007 \n","\n","Epoch 14\n","-------------------------------\n","train loss: 0.8775771260261536  [0/561]\n","Test Error: Avg loss: 1.283247470855713 \n","\n","Before LR :0.0038250000000000007, After LR : 0.0033500000000000005 \n","\n","Epoch 15\n","-------------------------------\n","train loss: 0.963119387626648  [0/561]\n","Test Error: Avg loss: 1.3296825885772705 \n","\n","Before LR :0.0033500000000000005, After LR : 0.0028750000000000004 \n","\n","Epoch 16\n","-------------------------------\n","train loss: 0.8364366292953491  [0/561]\n","Test Error: Avg loss: 1.1979478001594543 \n","\n","Before LR :0.0028750000000000004, After LR : 0.0024000000000000007 \n","\n","Epoch 17\n","-------------------------------\n","train loss: 0.7170053124427795  [0/561]\n","Test Error: Avg loss: 1.3514407277107239 \n","\n","Before LR :0.0024000000000000007, After LR : 0.0019250000000000007 \n","\n","Epoch 18\n","-------------------------------\n","train loss: 0.7708979845046997  [0/561]\n","Test Error: Avg loss: 1.2884839177131653 \n","\n","Before LR :0.0019250000000000007, After LR : 0.0014500000000000008 \n","\n","Epoch 19\n","-------------------------------\n","train loss: 0.6836555600166321  [0/561]\n","Test Error: Avg loss: 1.260527640581131 \n","\n","Before LR :0.0014500000000000008, After LR : 0.0009750000000000008 \n","\n","Epoch 20\n","-------------------------------\n","train loss: 0.5824719667434692  [0/561]\n","Test Error: Avg loss: 1.3081963062286377 \n","\n","Before LR :0.0009750000000000008, After LR : 0.0005000000000000002 \n","\n","Epoch 21\n","-------------------------------\n","train loss: 0.554572582244873  [0/561]\n","Test Error: Avg loss: 1.271693766117096 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 22\n","-------------------------------\n","train loss: 0.6273025274276733  [0/561]\n","Test Error: Avg loss: 1.2687830030918121 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 23\n","-------------------------------\n","train loss: 0.5171119570732117  [0/561]\n","Test Error: Avg loss: 1.286131590604782 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 24\n","-------------------------------\n","train loss: 0.512758731842041  [0/561]\n","Test Error: Avg loss: 1.2752770781517029 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 25\n","-------------------------------\n","train loss: 0.5306636691093445  [0/561]\n","Test Error: Avg loss: 1.2953484058380127 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 26\n","-------------------------------\n","train loss: 0.5458548665046692  [0/561]\n","Test Error: Avg loss: 1.278810739517212 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 27\n","-------------------------------\n","train loss: 0.49560630321502686  [0/561]\n","Test Error: Avg loss: 1.3560667634010315 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 28\n","-------------------------------\n","train loss: 0.5969523191452026  [0/561]\n","Test Error: Avg loss: 1.3027513027191162 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 29\n","-------------------------------\n","train loss: 0.45831096172332764  [0/561]\n","Test Error: Avg loss: 1.3229413032531738 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Epoch 30\n","-------------------------------\n","train loss: 0.5271658897399902  [0/561]\n","Test Error: Avg loss: 1.33486807346344 \n","\n","Before LR :0.0005000000000000002, After LR : 0.0005000000000000002 \n","\n","Done!\n"]}],"source":["#torch.autograd.set_detect_anomaly(True)\n","loss_list = []\n","for t in range(N_EPOCHS):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader_mask, model_mask,  loss_fn, opt)\n","    val_loss = test_loop(valid_dataloader_mask, model_mask, loss_fn)\n","    loss_list.append(val_loss)\n","    before_lr = opt.param_groups[0][\"lr\"]\n","    scheduler.step()\n","    after_lr = opt.param_groups[0][\"lr\"]\n","    print(f\"Before LR :{before_lr}, After LR : {after_lr} \\n\")\n","print(\"Done!\")"]},{"cell_type":"code","source":["plt.plot(loss_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"_YYqscaoooox","executionInfo":{"status":"ok","timestamp":1680540813127,"user_tz":-120,"elapsed":1135,"user":{"displayName":"Alice Simon","userId":"17575275506784402592"}},"outputId":"b092fbc0-6ae1-49c7-dd4d-1222525c6bbe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f9cfde4fc10>]"]},"metadata":{},"execution_count":110},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIDUSgtE0rTN"},"outputs":[],"source":["#torch.save(model_mask.state_dict(), '/content/drive/MyDrive/Projet_DL/state_dict/mask_only/pretrained_Unet_10_epochs_10-3_bs50')"]},{"cell_type":"markdown","metadata":{"id":"XNLQSvs-ropf"},"source":["## Model for label prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w88Pon-kiFNc"},"outputs":[],"source":["from torchvision.io import read_image\n","from torchvision.models import resnet50, ResNet50_Weights\n","\n","\n","# Step 1: Initialize model with the best available weights\n","weights = ResNet50_Weights.DEFAULT\n","model_label = resnet50(weights=weights)\n","num_features = model_label.fc.in_features\n","model_label.fc = nn.Linear(num_features, 3)\n","\n","\n","# Step 2: Initialize the inference transforms\n","preprocess = weights.transforms()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ_wPSOIi1v0"},"outputs":[],"source":["train_dataset_label = CustomDataset_label(train_df, us_transform, preprocess)\n","valid_dataset_label = CustomDataset_label(valid_df, us_transform, preprocess)\n","test_dataset_label = CustomDataset_label(test_df, us_transform, preprocess)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psyi1LPblfie"},"outputs":[],"source":["BATCH_SIZE = 10\n","\n","train_dataloader_label = DataLoader(dataset = train_dataset_label, batch_size = BATCH_SIZE, shuffle = True)\n","valid_dataloader_label = DataLoader(dataset = valid_dataset_label, batch_size = BATCH_SIZE, shuffle = False)\n","test_dataloader_label = DataLoader(dataset = test_dataset_label, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUTScyZsropi"},"outputs":[],"source":["N_EPOCHS = 10\n","LR = 1e-3\n","\n","model_label = model_label.to(device)\n","loss_fn = nn.CrossEntropyLoss() # Sigmoid layer and the BCELoss in one single class.\n","opt = optim.Adam(model_label.parameters(), lr = LR)"]},{"cell_type":"code","source":["model_label"],"metadata":{"id":"eL3LN4oyfvzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HchbAVQ9yciz"},"outputs":[],"source":["def train_loop_label(dataloader, model, loss_fn, opt):\n","    size = len(dataloader.dataset)\n","    \n","    for batch, (mask, label) in enumerate(dataloader):\n","        mask = mask.to(device)\n","        label = label.to(device)\n","\n","        # Compute prediction and loss\n","        label_logits = model(mask)\n","        \n","        loss_label =  loss_fn(label_logits, label.argmax(1))\n","        opt.zero_grad()\n","        loss_label.backward()\n","        \n","        opt.step()\n","\n","        # Backpropagation\n","        \"\"\"\n","        optimizer.zero_grad()\n","        loss_mask.backward(retain_graph = True)\n","        loss_label.backward()\n","        optimizer.step()\n","        \"\"\"     \n","\n","        if batch % 50 == 0:\n","            loss_label, current = loss_label.item(), batch * len(mask)\n","            print(f\"train label loss: {loss_label} [{current}/{size}]\")\n","\n","\n","def test_loop_label(dataloader, model, loss_fn, create_list = False):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","    true_label_list = []\n","    true_label = []\n","    pred_label = []\n","    with torch.no_grad():\n","        \n","        for mask, label in dataloader:\n","            if create_list == True:\n","              true_label_list += label.tolist()\n","              \n","            mask = mask.to(device)\n","            label = label.to(device)            \n","\n","            label_logits = model(mask)\n","            loss_label =  loss_fn(label_logits, label.argmax(1))\n","            \n","            test_loss += loss_label.item()\n","            correct += (label.argmax(1) == label_logits.argmax(1)).type(torch.float).sum().item()\n","\n","            if create_list == True:\n","              for pred in label_logits:\n","                argmax = torch.argmax(pred)\n","                if argmax == 0: pred_label += [\"Normal\"]\n","                elif argmax == 1: pred_label+= [\"Benign\"]\n","                else: pred_label+= [\"Malignant\"]\n","\n","    if create_list == True:\n","      for label in true_label_list:\n","        if label == list([1,0,0]): true_label.append('Normal')\n","        elif label == list([0,1,0]): true_label.append('Benign')\n","        else: true_label.append('Malignant')\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss} \\n\")\n","    print(f\"Test Error Label : {test_loss};  Accuracy: {(100*correct):>0.1f}% \\n\")\n","    if create_list == True:\n","      return test_loss, true_label, pred_label\n","    else: \n","      return test_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoNzqh3Eropk"},"outputs":[],"source":["#torch.autograd.set_detect_anomaly(True)\n","loss_list = []\n","for t in range(N_EPOCHS-1):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop_label(train_dataloader_label, model_label,  loss_fn, opt)\n","    val_loss = test_loop_label(valid_dataloader_label, model_label, loss_fn)\n","    loss_list.append(val_loss)\n","\n","print(f\"Epoch final\\n-------------------------------\")\n","train_loop_label(train_dataloader_label, model_label,  loss_fn, opt)\n","val_loss, true_label, pred_label = test_loop_label(valid_dataloader_label, model_label, loss_fn, create_list = True)\n","loss_list.append(val_loss)\n","\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44j5CNt-ropl"},"outputs":[],"source":["plt.plot(loss_list)"]},{"cell_type":"code","source":["test_loss, true_label_val, pred_label_val = test_loop_label(valid_dataloader_label, model_label, loss_fn, create_list = True)"],"metadata":{"id":"lpuNRTJYtFEY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpOs-VBggRDI"},"outputs":[],"source":["# Visualisation sur le dataset de validation\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt  \n","\n","cm = sklearn.metrics.confusion_matrix(true_label_val, pred_label_val)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix'); \n","ax.xaxis.set_ticklabels(['Benign', 'Malignant', 'Normal']); ax.yaxis.set_ticklabels(['Benign', 'Malignant', 'Normal']);"]},{"cell_type":"code","source":["# Visulisation sur le dataset de test\n","\n","test_loss, true_label_test, pred_label_test = test_loop_label(test_dataloader_label, model_label, loss_fn, create_list = True)\n","\n","cm_test = sklearn.metrics.confusion_matrix(true_label_test, pred_label_test)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm_test, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix for testing dataset'); \n","ax.xaxis.set_ticklabels(['Benign', 'Malignant', 'Normal']); ax.yaxis.set_ticklabels(['Benign', 'Malignant', 'Normal']);"],"metadata":{"id":"BmH1tnkGejv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRK1f_cIropm"},"outputs":[],"source":["\n","#torch.save(model_label.state_dict(), '/content/drive/MyDrive/Projet_DL/state_dict/label_only/pretrained_ResNet50_10_epochs_10-3_bs10')"]},{"cell_type":"markdown","metadata":{"id":"aB2yDBwOropn"},"source":["## Model Predictions"]},{"cell_type":"markdown","metadata":{"id":"NaV2b6x91Aik"},"source":["### Mask prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LLSkPzaropo"},"outputs":[],"source":["PATH_mask = '/content/drive/MyDrive/Projet_DL/state_dict/mask_only/pretrained_unet_20_epochs_10-3_bs100_test'\n","\n","Encoder = 'resnet34'\n","Weights = 'imagenet'\n","\n","model_mask = smp.Unet(\n","    encoder_name = Encoder,\n","    encoder_weights = Weights,\n","    in_channels = 3,\n","    classes = 1, # tumeur \n","    activation = None,\n",")\n","\n","model_mask = model_mask.to(device)\n","model_mask.load_state_dict(torch.load(PATH_mask, map_location=torch.device('cpu')))\n","model_mask.eval()"]},{"cell_type":"markdown","metadata":{"id":"yFj9Lvx_1ExI"},"source":["### Label prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kydYB-QS1Lkp"},"outputs":[],"source":["PATH_label = '/content/drive/MyDrive/Projet_DL/state_dict/label_only/pretrained_ResNet50_10_epochs_10-3_bs10'\n","\n","weights = ResNet50_Weights.DEFAULT\n","model_label = resnet50(weights=weights)\n","num_features = model_label.fc.in_features\n","model_label.fc = nn.Linear(num_features, 3)\n","\n","model_label = model_label.to(device)\n","model_label.load_state_dict(torch.load(PATH_label, map_location=torch.device('cpu')))\n","model_label.eval()"]},{"cell_type":"code","source":["# visualisation des résultats pour ce modèle \n","\n","def visualization_predictions(pytorch_dataset, model_label, number = 8):\n","    \"\"\" Show random images with label from pytorch dataset.\"\"\"\n","\n","    figure = plt.figure(figsize= (10,20))\n","    cols, rows = 3, number \n","    for i in range(1, 3 * number + 1,3):\n","        \n","        sample_idx = torch.randint(len(pytorch_dataset), size=(1,)).item()\n","        mask_img, label = pytorch_dataset.__getitem__(sample_idx)\n","        #print(mask_img.shape)\n","        \n","        if label[0].item() == 1. : label = \"normal\" \n","        elif label[1].item() == 1. : label = \"benign\"\n","        elif  label[2].item() == 1. : label = \"malignant\"\n","        \n","        \n","        figure.add_subplot(rows, cols, i + 1)\n","        plt.title(f\"Target : {label}\")\n","        plt.axis(\"off\")\n","        plt.imshow(mask_img.permute(1, 2, 0).squeeze(),cmap='gray')\n","        \n","        mask_img = mask_img.to(device)\n","        mask_img = mask_img.unsqueeze_(0)\n","        #print(mask_img.shape)\n","\n","        label_pred = model_label(mask_img)\n","        print(label_pred)\n","        #print(torch.round(label_pred))\n","        #print(torch.argmax(torch.abs(label_pred)))\n","\n","\n","        if torch.argmax(label_pred).item() == 0. : print('label_pred = normal') \n","        elif torch.argmax(label_pred).item() == 1 : print('label_pred = benign') \n","        elif  torch.argmax(label_pred).item() == 2 : print('label_pred = malignant') \n","\n","        \n","    plt.show()"],"metadata":{"id":"DIxgKIndkIug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset_label = CustomDataset_label(train_df, us_transform, preprocess)\n","valid_dataset_label = CustomDataset_label(valid_df, us_transform, preprocess)\n","test_dataset_label = CustomDataset_label(test_df, us_transform, preprocess)"],"metadata":{"id":"2-KmSQBnkQa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualization_predictions(test_dataset_label, model_label, number = 8)"],"metadata":{"id":"eRGFIthxzDV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcQaAxsC1lfg"},"source":["### Visualisations "]},{"cell_type":"code","source":["def custom_threshold(x, threshold):\n","  return torch.nn.functional.threshold(torch.round(x+0.5-threshold), 0.5, 0)"],"metadata":{"id":"FOZzEZKawMGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HlGJqkjzropo"},"outputs":[],"source":["def visualization_predictions_final(pytorch_dataset, model_mask, model_label, number = 8):\n","    \"\"\" Show random images with label from pytorch dataset.\"\"\"\n","\n","    figure = plt.figure(figsize= (10,20))\n","    cols, rows = 3, number \n","    for i in range(1, 3 * number + 1,3):\n","        \n","        sample_idx = torch.randint(len(pytorch_dataset), size=(1,)).item()\n","        ultrasound_img, mask_img, label = pytorch_dataset.__getitem__(sample_idx)\n","        \n","        if label[0].item() == 1. : label = \"normal\" \n","        elif label[1].item() == 1. : label = \"benign\"\n","        elif  label[2].item() == 1. : label = \"malignant\"\n","        \n","        figure.add_subplot(rows, cols, i)\n","        plt.title(\"Ultrasound Image\")\n","        plt.axis(\"off\")\n","        plt.imshow(ultrasound_img.permute(1, 2, 0).squeeze(),cmap='gray')\n","        \n","        figure.add_subplot(rows, cols, i + 1)\n","        plt.title(f\"Target : {label}\")\n","        plt.axis(\"off\")\n","        plt.imshow(mask_img.permute(1, 2, 0).squeeze(),cmap='gray')\n","        \n","        figure.add_subplot(rows, cols, i + 2)\n","        ultrasound_img = ultrasound_img[None, :, :, :] # add dimension\n","        ultrasound_img = ultrasound_img.to(device) # load to gpu\n","        mask_pred = model_mask(ultrasound_img)\n","        mask_pred = torch.sigmoid(mask_pred)\n","        #mask_pred = torch.round(mask_pred)\n","        mask_pred = custom_threshold(mask_pred, 0.80)\n","\n","        mask_pred_RGB = mask_pred.squeeze_(0)\n","        mask_pred_RGB = mask_pred_RGB.repeat(3, 1, 1)\n","        mask_pred_RGB = mask_pred_RGB.unsqueeze_(0)\n","        #print(mask_pred_RGB.shape)\n","\n","        label_pred = model_label(mask_pred_RGB)\n","        print(label_pred)\n","        #label_pred = torch.sigmoid(label_pred)\n","        #print(label_pred)\n","        \n","\n","        mask_pred.unsqueeze_(dim = 0)\n","        mask_pred = torch.squeeze(mask_pred,dim = 0).cpu() # remove dimension and put on cpu\n","\n","        if label_pred[0][0].item() > 0. : label_pred = \"normal\" \n","        elif (torch.argmax(label_pred).item() == 1) or ((torch.argmax(label_pred).item() == 2) and (label_pred[0][1].item() > 0.)) : label_pred = \"benign\"\n","        elif  (torch.argmax(label_pred).item() == 2) and (label_pred[0][1].item() < 0.) : label_pred = \"malignant\"\n","\n","        #if torch.argmax(label_pred).item() == 0. : label_pred = 'normal' \n","        #elif torch.argmax(label_pred).item() == 1 : label_pred = 'benign' \n","        #elif  torch.argmax(label_pred).item() == 2 : label_pred = 'malignant' \n","\n","        plt.title(f\"Prediction :{label_pred}\")\n","        plt.axis(\"off\")\n","        plt.imshow(mask_pred.detach().permute(1, 2, 0).squeeze(),cmap='gray')\n","        \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3dYx2GG4K1Z"},"outputs":[],"source":["test_dataset_mask = CustomDataset_mask(test_df, us_transform, mask_transform, print_label = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RypI8VAqropp"},"outputs":[],"source":["_ = torch.manual_seed(25)\n","\n","visualization_predictions_final(test_dataset_mask, model_mask, model_label, number = 15)"]},{"cell_type":"markdown","source":["### Prédictions combinées : matrices de confusion\n"],"metadata":{"id":"4XaGMiLvgg7P"}},{"cell_type":"code","source":["test_dataset_mask = CustomDataset_mask(test_df, us_transform, mask_transform, print_label = True)\n","test_dataloader_mask = DataLoader(dataset = test_dataset_mask, batch_size = BATCH_SIZE, shuffle = False)"],"metadata":{"id":"67e55SaFEwOO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test_combined_model(dataloader, model_mask, model_label, create_list = False):\n","    size = len(dataloader.dataset)\n","\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","    true_label_list = []\n","    true_label = []\n","    pred_label = []\n","    with torch.no_grad():\n","        \n","        for ultrasound, mask, label in dataloader:\n","            if create_list == True:\n","              true_label_list += label.tolist()\n","\n","            ultrasound = ultrasound.to(device) \n","            mask = mask.to(device)\n","            label = label.to(device)\n","            \n","            mask_pred = model_mask(ultrasound)\n","            mask_pred = torch.sigmoid(mask_pred)\n","            #mask_pred = torch.round(mask_pred)\n","            mask_pred = custom_threshold(mask_pred, 0.5)\n","\n","            mask_pred_RGB = mask_pred.repeat(1, 3, 1, 1)\n","\n","            label_logits = model_label(mask_pred_RGB)\n","            \n","            correct += (label.argmax(1) == label_logits.argmax(1)).type(torch.float).sum().item()\n","\n","            if create_list == True:\n","              for label_pred in label_logits:\n","                #print(label_pred)\n","                argmax = torch.argmax(label_pred)\n","                #if argmax == 0: pred_label += [\"Normal\"]\n","                #elif argmax == 1: pred_label+= [\"Benign\"]\n","                #else: pred_label+= [\"Malignant\"]\n","                if label_pred[0].item() > 0. : pred_label.append(\"Normal\")\n","                elif (torch.argmax(label_pred).item() == 1) or ((torch.argmax(label_pred).item() == 2) and (label_pred[1].item() > 0.)) : pred_label.append(\"Benign\")\n","                else : pred_label.append(\"Malignant\")\n","\n","    if create_list == True:\n","      for label in true_label_list:\n","        if label == list([1,0,0]): true_label.append('Normal')\n","        elif label == list([0,1,0]): true_label.append('Benign')\n","        else: true_label.append('Malignant')\n","      \n","      print(len(true_label))\n","      print(len(pred_label))\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss} \\n\")\n","    print(f\"Test Error Label : {test_loss};  Accuracy: {(100*correct):>0.1f}% \\n\")\n","    if create_list == True:\n","      return test_loss, true_label, pred_label\n","    else: \n","      return test_loss"],"metadata":{"id":"0ax6hsc4fM8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sur le dataset de train \n","\n","test_loss, true_label_test, pred_label_test = test_combined_model(test_dataloader_mask, model_mask, model_label, create_list = True)"],"metadata":{"id":"S7peRCwgfQOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm_test = sklearn.metrics.confusion_matrix(true_label_test, pred_label_test)\n","\n","ax= plt.subplot()\n","sns.heatmap(cm_test, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n","ax.set_title('Confusion Matrix for testing dataset - Threasold = 0.5'); \n","ax.xaxis.set_ticklabels(['Benign', 'Malignant', 'Normal']); ax.yaxis.set_ticklabels(['Benign', 'Malignant', 'Normal']);"],"metadata":{"id":"a7QfLK_bfTp2"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["XNLQSvs-ropf","y3mbuZagroph"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}